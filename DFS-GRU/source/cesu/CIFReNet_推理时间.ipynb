{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import collections\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from argparse import ArgumentParser\n",
    "from torch.nn.modules.utils import _pair\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models\n",
    "cudnn.benchmark = True\n",
    "\n",
    "from torch.nn import init\n",
    "try:\n",
    "    torch._utils._rebuild_tensor_v2\n",
    "except AttributeError:\n",
    "    def _rebuild_tensor_v2(storage, storage_offset, size, stride, requires_grad, backward_hooks):\n",
    "        tensor = torch._utils._rebuild_tensor(storage, storage_offset, size, stride)\n",
    "        tensor.requires_grad = requires_grad\n",
    "        tensor._backward_hooks = backward_hooks\n",
    "        return tensor\n",
    "    torch._utils._rebuild_tensor_v2 = _rebuild_tensor_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载预训练的mobilenetv2\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio, dalited):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.d = dalited\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # pw\n",
    "            nn.Conv2d(inp, inp * expand_ratio, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(inp * expand_ratio),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # dw\n",
    "            nn.Conv2d(inp * expand_ratio, inp * expand_ratio, 3, stride, padding=self.d, dilation=self.d, groups=inp * expand_ratio, bias=False),\n",
    "            nn.BatchNorm2d(inp * expand_ratio),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(inp * expand_ratio, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.interverted_residual_setting = [\n",
    "            # t, c, n, s, d\n",
    "            [1, 16, 1, 1, 1],    # 1/2\n",
    "            [6, 24, 2, 2, 1],    # 1/4\n",
    "            [6, 32, 3, 2, 1],    # 1/8\n",
    "            [6, 64, 4, 1, 2],    # 1/8\n",
    "            [6, 96, 3, 1, 3],    # 1/8\n",
    "            [6, 160, 3, 1, 5],   # 1/8\n",
    "            [6, 320, 1, 1, 7],  # 1/8\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        input_channel = int(32 * width_mult)\n",
    "        self.last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280\n",
    "        self.features = [conv_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s ,d in self.interverted_residual_setting:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(InvertedResidual(input_channel, output_channel, s, t,d))\n",
    "                else:\n",
    "                    self.features.append(InvertedResidual(input_channel, output_channel, 1, t,d))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
    "        self.features.append(nn.AvgPool2d(input_size/32))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(self.last_channel, n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, self.last_channel)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "                \n",
    "net = MobileNetV2(n_class=1000)\n",
    "mobilenet_v2 = list(net.features.children())\n",
    "len(mobilenet_v2)\n",
    "\n",
    "def channel_shuffle(x, groups):\n",
    "    batchsize, num_channels, height, width = x.data.size()\n",
    "    assert (num_channels % groups == 0)\n",
    "    channels_per_group = num_channels // groups\n",
    "    # reshape\n",
    "    x = x.view(batchsize, groups, channels_per_group, height, width)\n",
    "    # transpose\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "    # flatten\n",
    "    x = x.view(batchsize, -1, height, width)\n",
    "    return x\n",
    "\n",
    "class ShuffleBlock(nn.Module):\n",
    "    def __init__(self, groups):\n",
    "        super(ShuffleBlock, self).__init__()\n",
    "        self.groups = groups\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]'''\n",
    "        N,C,H,W = x.size()\n",
    "        g = self.groups\n",
    "        return x.view(N,g,int(C/g),H,W).permute(0,2,1,3,4).contiguous().view(N,C,H,W)\n",
    "\n",
    "\n",
    "class ABN(nn.Sequential):\n",
    "    def __init__(self, num_features):\n",
    "        super(ABN, self).__init__(OrderedDict([\n",
    "            (\"bn\",  nn.BatchNorm2d(num_features,eps=1e-05, momentum=0.1, affine=True)),\n",
    "            (\"act\", nn.PReLU(num_features))\n",
    "        ]))\n",
    "\n",
    "class DSP(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, c_tag=0.2, groups=4, dilation=(1,2,3,4)):\n",
    "        super(DSP, self).__init__()\n",
    "        \n",
    "        self.out_c = round(c_tag * outplanes)\n",
    "        \n",
    "        self.down = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, self.out_c, 1, stride=1, groups=groups, bias=False),\n",
    "                ABN(self.out_c)\n",
    "          )\n",
    "        \n",
    "        self.pool =  nn.Sequential(\n",
    "                                nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                nn.Conv2d(self.out_c, self.out_c, 1, stride=1),\n",
    "                                nn.BatchNorm2d(self.out_c,eps=1e-05, momentum=0.1, affine=True)\n",
    "            )\n",
    "        \n",
    "        self.branch_1 = nn.Sequential(\n",
    "                nn.Conv2d(self.out_c, self.out_c, kernel_size=3, padding=dilation[0], dilation = dilation[0],groups=self.out_c, bias=False),\n",
    "                ABN(self.out_c),\n",
    "                nn.Conv2d(self.out_c, self.out_c, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(self.out_c,eps=1e-05, momentum=0.1, affine=True)\n",
    "        )\n",
    "        self.branch_2 = nn.Sequential(\n",
    "                nn.Conv2d(self.out_c, self.out_c, kernel_size=3, padding=dilation[1],dilation = dilation[1],groups=self.out_c, bias=False),\n",
    "                ABN(self.out_c),\n",
    "                nn.Conv2d(self.out_c, self.out_c, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(self.out_c,eps=1e-05, momentum=0.1, affine=True)\n",
    "            )\n",
    "        self.branch_3 = nn.Sequential(\n",
    "                nn.Conv2d(self.out_c, self.out_c, kernel_size=3, padding=dilation[2],dilation = dilation[2],groups=self.out_c, bias=False),\n",
    "                ABN(self.out_c),\n",
    "                nn.Conv2d(self.out_c, self.out_c, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(self.out_c,eps=1e-05, momentum=0.1, affine=True)\n",
    "        )\n",
    "        \n",
    "        self.branch_4 = nn.Sequential(\n",
    "                nn.Conv2d(self.out_c, self.out_c, kernel_size=3, padding=dilation[3],dilation = dilation[3],groups=self.out_c, bias=False),\n",
    "                ABN(self.out_c),\n",
    "                nn.Conv2d(self.out_c, self.out_c, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(self.out_c,eps=1e-05, momentum=0.1, affine=True)\n",
    "        )\n",
    "       \n",
    "        self.groups = groups\n",
    "        \n",
    "        self.module_act = nn.PReLU(outplanes)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        input_x = x\n",
    "        x_size = x.size()\n",
    "        x= self.down(x)\n",
    "        branch_1 = self.branch_1(x)\n",
    "        branch_2 = self.branch_2(x)\n",
    "        branch_3 = self.branch_3(x)\n",
    "        branch_4 = self.branch_4(x)\n",
    "        pool = F.upsample(self.pool(x),x_size[2:], mode= \"bilinear\")\n",
    "        out = channel_shuffle(torch.cat((branch_1,branch_2,branch_3,branch_4,pool), 1), self.groups)\n",
    "        \n",
    "        if out.size() == input_x.size():\n",
    "            out = out + input_x\n",
    "        return self.module_act(out)\n",
    "    \n",
    "class MCIM(nn.Module):\n",
    "    def __init__(self, in_chs = 320, out_chs = 320):\n",
    "        super(MCIM, self).__init__()\n",
    "        \n",
    "        self.pool =  nn.Sequential(\n",
    "                                nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                nn.Conv2d(in_chs, 80, 1, stride=1),\n",
    "                                nn.BatchNorm2d(80),\n",
    "                                nn.LeakyReLU(0.1)\n",
    "            )\n",
    "        \n",
    "        self.conv_small = DSP(in_chs, out_chs, dilation = (1,2,3,5))\n",
    "        \n",
    "        self.conv_middle = DSP(out_chs, out_chs, dilation = (7,9,11,13))\n",
    "\n",
    "        self.conv_larger = DSP(out_chs, out_chs, dilation = (17,19,21,23))\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        small = self.conv_small(x)\n",
    "        middle = self.conv_middle(small)\n",
    "        larger = self.conv_larger(middle)\n",
    "        pool = F.upsample(self.pool(x),x_size[2:], mode= \"bilinear\")\n",
    "        output = small+middle+larger\n",
    "        output = torch.cat([output,pool],1)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "#语义分割模型 mobilenet_v2\n",
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "class Attention_Block(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(Attention_Block, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.channel_excitation = nn.Sequential(nn.Linear(channel, int(channel//reduction)),\n",
    "                                                nn.ReLU(inplace=True),                                             \n",
    "                                                nn.Linear(int(channel//reduction), channel),\n",
    "                                                nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        bahs, chs, _, _ = x.size()\n",
    "        chn_se = self.avg_pool(x).view(bahs, chs)        \n",
    "        return self.channel_excitation(chn_se).view(bahs, chs, 1, 1)\n",
    "\n",
    "                \n",
    "class M2_semantic(nn.Module):\n",
    "    def __init__(self, num_classes=19):\n",
    "        super(M2_semantic, self).__init__()\n",
    "        \n",
    "        # building inverted residual blocks\n",
    "        self.mod1 = mobilenet_v2[0]\n",
    "        self.mod2 = mobilenet_v2[1]\n",
    "        self.mod3 = nn.Sequential(mobilenet_v2[2],mobilenet_v2[3])\n",
    "        self.mod4 = nn.Sequential(mobilenet_v2[4],mobilenet_v2[5],mobilenet_v2[6])\n",
    "        self.mod5 = nn.Sequential(mobilenet_v2[7],mobilenet_v2[8],mobilenet_v2[9],mobilenet_v2[10])\n",
    "        self.mod6 = nn.Sequential(mobilenet_v2[11],mobilenet_v2[12],mobilenet_v2[13])\n",
    "        self.mod7 = nn.Sequential(mobilenet_v2[14],mobilenet_v2[15],mobilenet_v2[16])\n",
    "        self.mod8 = mobilenet_v2[17]\n",
    "        \n",
    "        self.LRM =  nn.Sequential(\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding = 1, groups = 32), \n",
    "                        ABN(32),\n",
    "                        nn.Conv2d(32, 160, kernel_size=1),    \n",
    "                        ABN(160)\n",
    "                            )\n",
    "        \n",
    "        self.multi_scale = MCIM(320, 320)\n",
    "        \n",
    "        self.attention = Attention_Block(160)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(400, 256, kernel_size = 1, stride = 1,groups =16),\n",
    "            ShuffleBlock(16),\n",
    "            nn.BatchNorm2d(256,eps=1e-05, momentum=0.1, affine=True),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "        initialize_weights(self.LRM, self.attention, self.multi_scale, self.final)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()  \n",
    "        stg0 = self.mod1(x)         # torch.Size([1, 32, 112, 224])\n",
    "        \n",
    "        stg1 = self.mod2(stg0)      # torch.Size([1, 16, 112, 224])\n",
    "        stg2 = self.mod3(stg1)      # torch.Size([1, 24, 56, 112])     \n",
    "        stg3 = self.mod4(stg2)  # torch.Size([1, 32, 28, 56]) \n",
    "        \n",
    "        LRM = self.LRM(stg3)  # torch.Size([1, 32, 28, 56])\n",
    "        \n",
    "        stg4 = self.mod5(stg3)  # torch.Size([1, 64, 28, 56])\n",
    "        stg5 = self.mod6(stg4) # torch.Size([1, 96, 28, 56])   \n",
    "        stg6 = self.mod7(stg5)  # torch.Size([1, 160, 28, 56])\n",
    "        \n",
    "        attention = self.attention(stg6)\n",
    "        \n",
    "        stg6 = torch.mul(attention,LRM) + stg6\n",
    "        \n",
    "        stg7 = self.mod8(stg6)  # torch.Size([1, 320, 28, 56])\n",
    "\n",
    "        multi_scale = self.multi_scale(stg7)\n",
    "        \n",
    "#         print(modified_aspp.size())\n",
    "        out = self.final(multi_scale)\n",
    "        \n",
    "        return F.upsample(out, x_size[2:], mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    model = M2_semantic(num_classes=19).cuda()\n",
    "    model.eval()\n",
    "\n",
    "#     images = torch.randn(1, 3, 1024, 448)\n",
    "    images = torch.randn(1, 3, 1024, 512)\n",
    "#     images = torch.randn(1, 3, 713, 713)\n",
    "#     images = torch.randn(1, 3, 512, 512)\n",
    "#     images = torch.randn(1, 3, 640, 360)\n",
    "  \n",
    "    images = images.cuda()#.half()\n",
    "\n",
    "    time_train = []\n",
    "\n",
    "    i=0\n",
    "\n",
    "    while(True):\n",
    "        if i == 30:\n",
    "            break\n",
    "            \n",
    "        start_time = time.time()\n",
    "\n",
    "        inputs = Variable(images, volatile=True)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "\n",
    "        torch.cuda.synchronize()    #wait for cuda to finish (cuda is asynchronous!)\n",
    "\n",
    "        if i!=0:    #first run always takes some time for setup\n",
    "            fwt = time.time() - start_time\n",
    "            time_train.append(fwt)\n",
    "            print (\"Forward time per img (b=%d): %.3f (Mean: %.3f)\" % (1, fwt/1, sum(time_train) / len(time_train) /1))\n",
    "        \n",
    "        time.sleep(1)   #to avoid overheating the GPU too much\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward time per img (b=1): 0.017 (Mean: 0.017)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.017)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.013 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.013 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.013 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.013 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.013 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.013 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.015)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.016)\n"
     ]
    }
   ],
   "source": [
    "#     images = torch.randn(1, 3, 640, 360)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward time per img (b=1): 0.017 (Mean: 0.017)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.017)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.017)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.017)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.017)\n",
      "Forward time per img (b=1): 0.031 (Mean: 0.019)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.019)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.019)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.017)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.017)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.016 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n",
      "Forward time per img (b=1): 0.017 (Mean: 0.018)\n"
     ]
    }
   ],
   "source": [
    "#     images = torch.randn(1, 3, 512, 512)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward time per img (b=1): 0.031 (Mean: 0.031)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.030 (Mean: 0.030)\n"
     ]
    }
   ],
   "source": [
    "# images = torch.randn(1, 3, 713, 713)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward time per img (b=1): 0.028 (Mean: 0.028)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.027)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.027)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.028 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n",
      "Forward time per img (b=1): 0.026 (Mean: 0.026)\n"
     ]
    }
   ],
   "source": [
    "# images = torch.randn(1, 3, 1024, 448)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward time per img (b=1): 0.031 (Mean: 0.031)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.030)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.031 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n",
      "Forward time per img (b=1): 0.029 (Mean: 0.029)\n"
     ]
    }
   ],
   "source": [
    "# images = torch.randn(1, 3, 1024, 512)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
